<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>3. Scrapy常用命令实战 | Introduction</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../scrapy/4.html" />
    
    
    <link rel="prev" href="../scrapy/2.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="4"
        data-chapter-title="3. Scrapy常用命令实战"
        data-filepath="scrapy/3.md"
        data-basepath=".."
        data-revision="Sun Jan 28 2018 19:48:10 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Introduction
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        Scrapy简介
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2" data-path="scrapy/index.html">
            
                
                    <a href="../scrapy/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        1. 认识Scrapy框架
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3" data-path="scrapy/2.html">
            
                
                    <a href="../scrapy/2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        2. Scrapy安装和使用
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="4" data-path="scrapy/3.html">
            
                
                    <a href="../scrapy/3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        3. Scrapy常用命令实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5" data-path="scrapy/4.html">
            
                
                    <a href="../scrapy/4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        4. Scrapy实现当当网商品爬虫实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6" data-path="scrapy/5.html">
            
                
                    <a href="../scrapy/5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        5. Scrapy模拟登录实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7" data-path="scrapy/6.html">
            
                
                    <a href="../scrapy/6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        6. Scrapy新闻爬虫项目实战上
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8" data-path="scrapy/7.html">
            
                
                    <a href="../scrapy/7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        7. Scrapy新闻爬虫项目实战下
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9" data-path="scrapy/8.html">
            
                
                    <a href="../scrapy/8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        8. Scrapy豆瓣网登录爬虫与验证码识别项目实战1
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10" data-path="scrapy/9.html">
            
                
                    <a href="../scrapy/9.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        9. Scrapy豆瓣网登录爬虫与验证码识别项目实战2
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="11" data-path="scrapy/10.html">
            
                
                    <a href="../scrapy/10.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>11.</b>
                        
                        10. 如何在Urillib中使用Xpath表达式
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12" data-path="week2/index.html">
            
                
                    <a href="../week2/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.</b>
                        
                        Scrapy第二周实战
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="12.1" data-path="week2/1.html">
            
                
                    <a href="../week2/1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.1.</b>
                        
                        1. Scrapy与Urllib整合实现京东商品
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.2" data-path="week2/2.html">
            
                
                    <a href="../week2/2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.2.</b>
                        
                        2. 淘宝商品爬虫项目实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.3" data-path="week2/3.html">
            
                
                    <a href="../week2/3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.3.</b>
                        
                        3. BeautifulSoup基础实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.4" data-path="week2/4.html">
            
                
                    <a href="../week2/4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.4.</b>
                        
                        4. PhantomJS基础实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.5" data-path="week2/5.html">
            
                
                    <a href="../week2/5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.5.</b>
                        
                        5. 腾讯动漫项目爬虫实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.6" data-path="week2/6.html">
            
                
                    <a href="../week2/6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.6.</b>
                        
                        6. Docker基础
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.7" data-path="week2/7.html">
            
                
                    <a href="../week2/7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.7.</b>
                        
                        7. Redis的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.8" data-path="week2/8.html">
            
                
                    <a href="../week2/8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.8.</b>
                        
                        8. 分布式爬虫的实战
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >Introduction</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="3scrapy&#x5E38;&#x7528;&#x547D;&#x4EE4;&#x5B9E;&#x6218;">3.Scrapy&#x5E38;&#x7528;&#x547D;&#x4EE4;&#x5B9E;&#x6218;</h1>
<h3 id="scrapy-&#x547D;&#x4EE4;-&#x5206;&#x4E3A;&#x4E24;&#x79CD;&#xFF1A;&#x5168;&#x5C40;&#x547D;&#x4EE4;-&#x548C;-&#x9879;&#x76EE;&#x547D;&#x4EE4;&#x3002;">Scrapy &#x547D;&#x4EE4; &#x5206;&#x4E3A;&#x4E24;&#x79CD;&#xFF1A;<code>&#x5168;&#x5C40;&#x547D;&#x4EE4;</code> &#x548C; <code>&#x9879;&#x76EE;&#x547D;&#x4EE4;</code>&#x3002;</h3>
<ul>
<li><p><code>&#x5168;&#x5C40;&#x547D;&#x4EE4;</code>&#xFF1A;&#x5728;&#x54EA;&#x91CC;&#x90FD;&#x80FD;&#x4F7F;&#x7528;&#x3002;</p>
</li>
<li><p><code>&#x9879;&#x76EE;&#x547D;&#x4EE4;</code>&#xFF1A;&#x5FC5;&#x987B;&#x5728;&#x722C;&#x866B;&#x9879;&#x76EE;&#x91CC;&#x9762;&#x624D;&#x80FD;&#x4F7F;&#x7528;&#x3002;</p>
</li>
</ul>
<h4 id="&#x5168;&#x5C40;&#x547D;&#x4EE4;">&#x5168;&#x5C40;&#x547D;&#x4EE4;</h4>
<pre><code>C:\Users\AOBO&gt;scrapy -h
Scrapy 1.2.1 - no active project

&#x4F7F;&#x7528;&#x683C;&#x5F0F;:
  scrapy &lt;command&gt; [options] [args]

&#x53EF;&#x7528;&#x7684;&#x547D;&#x4EE4;:
  bench         &#x6D4B;&#x8BD5;&#x672C;&#x5730;&#x786C;&#x4EF6;&#x6027;&#x80FD;&#xFF08;&#x5DE5;&#x4F5C;&#x539F;&#x7406;&#xFF1A;&#xFF09;&#xFF1A;scrapy bench
  commands
  fetch         &#x53D6;URL&#x4F7F;&#x7528;Scrapy&#x4E0B;&#x8F7D;
  genspider     &#x4EA7;&#x751F;&#x65B0;&#x7684;&#x8718;&#x86DB;&#x4F7F;&#x7528;&#x9884;&#x5148;&#x5B9A;&#x4E49;&#x7684;&#x6A21;&#x677F;
  runspider     &#x8FD0;&#x7528;&#x5355;&#x72EC;&#x4E00;&#x4E2A;&#x722C;&#x866B;&#x6587;&#x4EF6;&#xFF1A;scrapy runspider abc.py
  settings      &#x83B7;&#x53D6;&#x8BBE;&#x7F6E;&#x503C;
  shell         &#x8FDB;&#x5165;&#x4EA4;&#x4E92;&#x7EC8;&#x7AEF;&#xFF0C;&#x7528;&#x4E8E;&#x722C;&#x866B;&#x7684;&#x8C03;&#x8BD5;&#xFF08;&#x5982;&#x679C;&#x4F60;&#x4E0D;&#x8C03;&#x8BD5;&#xFF0C;&#x90A3;&#x4E48;&#x5C31;&#x4E0D;&#x5E38;&#x7528;&#xFF09;&#xFF1A;scrapy shell http://www.baidu.com --nolog&#xFF08;--nolog &#x4E0D;&#x663E;&#x793A;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;&#xFF09;
  startproject  &#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x722C;&#x866B;&#x9879;&#x76EE;&#xFF0C;&#x5982;&#xFF1A;scrapy startproject demo&#xFF08;demo &#x521B;&#x5EFA;&#x7684;&#x722C;&#x866B;&#x9879;&#x76EE;&#x7684;&#x540D;&#x5B57;&#xFF09;
  version       &#x67E5;&#x770B;&#x7248;&#x672C;&#xFF1A;&#xFF08;scrapy version&#xFF09;
  view          &#x4E0B;&#x8F7D;&#x4E00;&#x4E2A;&#x7F51;&#x9875;&#x7684;&#x6E90;&#x4EE3;&#x7801;&#xFF0C;&#x5E76;&#x5728;&#x9ED8;&#x8BA4;&#x7684;&#x6587;&#x672C;&#x7F16;&#x8F91;&#x5668;&#x4E2D;&#x6253;&#x5F00;&#x8FD9;&#x4E2A;&#x6E90;&#x4EE3;&#x7801;&#xFF1A;scrapy view http://www.aobossir.com/

  [ more ]      &#x4ECE;&#x9879;&#x76EE;&#x76EE;&#x5F55;&#x8FD0;&#x884C;&#x65F6;&#x53EF;&#x83B7;&#x5F97;&#x66F4;&#x591A;&#x547D;&#x4EE4;

&#x4F7F;&#x7528; &quot;scrapy &lt;command&gt; -h&quot; &#x8981;&#x67E5;&#x770B;&#x6709;&#x5173;&#x547D;&#x4EE4;&#x7684;&#x66F4;&#x591A;&#x4FE1;&#x606F;
</code></pre><h4 id="&#x9879;&#x76EE;&#x547D;&#x4EE4;&#xFF1A;">&#x9879;&#x76EE;&#x547D;&#x4EE4;&#xFF1A;</h4>
<pre><code>D:\BaiduYunDownload\first&gt;scrapy -h
Scrapy 1.2.1 - project: first

Usage:
  scrapy &lt;command&gt; [options] [args]

Available commands:
  bench         Run quick benchmark test
  check         Check spider contracts
  commands
  crawl         &#x8FD0;&#x884C;&#x4E00;&#x4E2A;&#x722C;&#x866B;&#x6587;&#x4EF6;&#x3002;&#xFF1A;scrapy crawl f1 &#x6216;&#x8005; scrapy crawl f1 --nolog
  edit          &#x4F7F;&#x7528;&#x7F16;&#x8F91;&#x5668;&#x6253;&#x5F00;&#x722C;&#x866B;&#x6587;&#x4EF6; &#xFF08;Windows&#x4E0A;&#x4F3C;&#x4E4E;&#x6709;&#x95EE;&#x9898;&#xFF0C;Linux&#x4E0A;&#x6CA1;&#x6709;&#x95EE;&#x9898;&#xFF09;&#xFF1A;scrapy edit f1
  fetch         Fetch a URL using the Scrapy downloader
  genspider     Generate new spider using pre-defined templates
  list          &#x5217;&#x51FA;&#x5F53;&#x524D;&#x722C;&#x866B;&#x9879;&#x76EE;&#x4E0B;&#x6240;&#x6709;&#x7684;&#x722C;&#x866B;&#x6587;&#x4EF6;&#xFF1A; scrapy list
  parse         Parse URL (using its spider) and print the results
  runspider     Run a self-contained spider (without creating a project)
  settings      &#x83B7;&#x53D6;&#x8BBE;&#x7F6E;&#x503C;
  shell         &#x8FDB;&#x5165;&#x4EA4;&#x4E92;&#x7EC8;&#x7AEF;&#xFF0C;&#x7528;&#x4E8E;&#x722C;&#x866B;&#x7684;&#x8C03;&#x8BD5;&#xFF08;&#x5982;&#x679C;&#x4F60;&#x4E0D;&#x8C03;&#x8BD5;&#xFF0C;&#x90A3;&#x4E48;&#x5C31;&#x4E0D;&#x5E38;&#x7528;&#xFF09;
  startproject  &#x521B;&#x5EFA;&#x4E00;&#x4E2A;&#x722C;&#x866B;&#x9879;&#x76EE;&#xFF0C;&#x5982;&#xFF1A;scrapy startproject demo&#xFF08;demo &#x521B;&#x5EFA;&#x7684;&#x722C;&#x866B;&#x9879;&#x76EE;&#x7684;&#x540D;&#x5B57;&#xFF09;
  version       &#x67E5;&#x770B;&#x7248;&#x672C;&#xFF1A;&#xFF08;scrapy version&#xFF09;
  view          &#x4E0B;&#x8F7D;&#x4E00;&#x4E2A;&#x7F51;&#x9875;&#x7684;&#x6E90;&#x4EE3;&#x7801;&#xFF0C;&#x5E76;&#x5728;&#x9ED8;&#x8BA4;&#x7684;&#x6587;&#x672C;&#x7F16;&#x8F91;&#x5668;&#x4E2D;&#x6253;&#x5F00;&#x8FD9;&#x4E2A;&#x6E90;&#x4EE3;&#x7801;

Use &quot;scrapy &lt;command&gt; -h&quot; to see more info about a command
</code></pre><h4 id="&#x3000;&#x5177;&#x4F53;&#x6848;&#x4F8B;&#xFF1A;">&#x3000;&#x5177;&#x4F53;&#x6848;&#x4F8B;&#xFF1A;</h4>
<ul>
<li>&#x67E5;&#x770B;&#x6240;&#x6709;&#x547D;&#x4EE4;</li>
</ul>
<pre><code>scrapy -h
</code></pre><ul>
<li>&#x67E5;&#x770B;&#x5E2E;&#x52A9;&#x4FE1;&#x606F;:</li>
</ul>
<pre><code>scapy --help
</code></pre><ul>
<li>&#x67E5;&#x770B;&#x7248;&#x672C;&#x4FE1;&#x606F;:</li>
</ul>
<pre><code>(venv)ql@ql:~$ scrapy version
Scrapy 1.1.2
(venv)ql@ql:~$ 
(venv)ql@ql:~$ scrapy version -v
Scrapy    : 1.1.2
lxml      : 3.6.4.0
libxml2   : 2.9.4
Twisted   : 16.4.0
Python    : 2.7.12 (default, Jul  1 2016, 15:12:24) - [GCC 5.4.0 20160609]
pyOpenSSL : 16.1.0 (OpenSSL 1.0.2g-fips  1 Mar 2016)
Platform  : Linux-4.4.0-36-generic-x86_64-with-Ubuntu-16.04-xenial
(venv)ql@ql:~$
</code></pre><ul>
<li>&#x65B0;&#x5EFA;&#x4E00;&#x4E2A;&#x5DE5;&#x7A0B;</li>
</ul>
<pre><code>scrapy startproject spider_name
</code></pre><ul>
<li>&#x6784;&#x5EFA;&#x722C;&#x866B;genspider(generator spider)</li>
<li>&#x4E00;&#x4E2A;&#x5DE5;&#x7A0B;&#x4E2D;&#x53EF;&#x4EE5;&#x5B58;&#x5728;&#x591A;&#x4E2A;spider, &#x4F46;&#x662F;&#x540D;&#x5B57;&#x5FC5;&#x987B;&#x552F;&#x4E00;</li>
</ul>
<pre><code>scrapy genspider name domain
#&#x5982;:
#scrapy genspider sohu sohu.org
</code></pre><ul>
<li>&#x67E5;&#x770B;&#x5F53;&#x524D;&#x9879;&#x76EE;&#x5185;&#x6709;&#x591A;&#x5C11;&#x722C;&#x866B;</li>
</ul>
<pre><code>scrapy list
</code></pre><ul>
<li>view&#x4F7F;&#x7528;&#x6D4F;&#x89C8;&#x5668;&#x6253;&#x5F00;&#x7F51;&#x9875;</li>
</ul>
<pre><code>scrapy view http://www.baidu.com

* shell&#x547D;&#x4EE4;, &#x8FDB;&#x5165;scrpay&#x4EA4;&#x4E92;&#x73AF;&#x5883;
</code></pre><h1 id="&#x8FDB;&#x5165;&#x8BE5;url&#x7684;&#x4EA4;&#x4E92;&#x73AF;&#x5883;">&#x8FDB;&#x5165;&#x8BE5;url&#x7684;&#x4EA4;&#x4E92;&#x73AF;&#x5883;</h1>
<p>scrapy shell <a href="http://www.dmoz.org/Computers/Programming/Languages/Python/Books/" target="_blank">http://www.dmoz.org/Computers/Programming/Languages/Python/Books/</a></p>
<pre><code>
*&#x4E4B;&#x540E;&#x4FBF;&#x8FDB;&#x5165;&#x4EA4;&#x4E92;&#x73AF;&#x5883;&#xFF0C;&#x6211;&#x4EEC;&#x4E3B;&#x8981;&#x4F7F;&#x7528;&#x8FD9;&#x91CC;&#x9762;&#x7684;response&#x547D;&#x4EE4;, &#x4F8B;&#x5982;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;
</code></pre><p>response.xpath()    #&#x62EC;&#x53F7;&#x91CC;&#x76F4;&#x63A5;&#x52A0;xpath&#x8DEF;&#x5F84;</p>
<pre><code>
* runspider&#x547D;&#x4EE4;&#x7528;&#x4E8E;&#x76F4;&#x63A5;&#x8FD0;&#x884C;&#x521B;&#x5EFA;&#x7684;&#x722C;&#x866B;, &#x5E76;&#x4E0D;&#x4F1A;&#x8FD0;&#x884C;&#x6574;&#x4E2A;&#x9879;&#x76EE;
</code></pre><p>scrapy runspider &#x722C;&#x866B;&#x540D;&#x79F0;
```</p>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../scrapy/2.html" class="navigation navigation-prev " aria-label="Previous page: 2. Scrapy安装和使用"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../scrapy/4.html" class="navigation navigation-next " aria-label="Next page: 4. Scrapy实现当当网商品爬虫实战"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
