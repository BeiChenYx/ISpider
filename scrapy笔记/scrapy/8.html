<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>8. Scrapy豆瓣网登录爬虫与验证码识别项目实战1 | Introduction</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../scrapy/9.html" />
    
    
    <link rel="prev" href="../scrapy/7.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="9"
        data-chapter-title="8. Scrapy豆瓣网登录爬虫与验证码识别项目实战1"
        data-filepath="scrapy/8.md"
        data-basepath=".."
        data-revision="Sun Jan 28 2018 19:48:10 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Introduction
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        Scrapy简介
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2" data-path="scrapy/index.html">
            
                
                    <a href="../scrapy/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        1. 认识Scrapy框架
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3" data-path="scrapy/2.html">
            
                
                    <a href="../scrapy/2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        2. Scrapy安装和使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4" data-path="scrapy/3.html">
            
                
                    <a href="../scrapy/3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        3. Scrapy常用命令实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5" data-path="scrapy/4.html">
            
                
                    <a href="../scrapy/4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        4. Scrapy实现当当网商品爬虫实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6" data-path="scrapy/5.html">
            
                
                    <a href="../scrapy/5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        5. Scrapy模拟登录实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7" data-path="scrapy/6.html">
            
                
                    <a href="../scrapy/6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        6. Scrapy新闻爬虫项目实战上
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8" data-path="scrapy/7.html">
            
                
                    <a href="../scrapy/7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        7. Scrapy新闻爬虫项目实战下
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="9" data-path="scrapy/8.html">
            
                
                    <a href="../scrapy/8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        8. Scrapy豆瓣网登录爬虫与验证码识别项目实战1
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10" data-path="scrapy/9.html">
            
                
                    <a href="../scrapy/9.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        9. Scrapy豆瓣网登录爬虫与验证码识别项目实战2
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="11" data-path="scrapy/10.html">
            
                
                    <a href="../scrapy/10.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>11.</b>
                        
                        10. 如何在Urillib中使用Xpath表达式
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12" data-path="week2/index.html">
            
                
                    <a href="../week2/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.</b>
                        
                        Scrapy第二周实战
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="12.1" data-path="week2/1.html">
            
                
                    <a href="../week2/1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.1.</b>
                        
                        1. Scrapy与Urllib整合实现京东商品
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.2" data-path="week2/2.html">
            
                
                    <a href="../week2/2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.2.</b>
                        
                        2. 淘宝商品爬虫项目实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.3" data-path="week2/3.html">
            
                
                    <a href="../week2/3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.3.</b>
                        
                        3. BeautifulSoup基础实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.4" data-path="week2/4.html">
            
                
                    <a href="../week2/4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.4.</b>
                        
                        4. PhantomJS基础实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.5" data-path="week2/5.html">
            
                
                    <a href="../week2/5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.5.</b>
                        
                        5. 腾讯动漫项目爬虫实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.6" data-path="week2/6.html">
            
                
                    <a href="../week2/6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.6.</b>
                        
                        6. Docker基础
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.7" data-path="week2/7.html">
            
                
                    <a href="../week2/7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.7.</b>
                        
                        7. Redis的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.8" data-path="week2/8.html">
            
                
                    <a href="../week2/8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.8.</b>
                        
                        8. 分布式爬虫的实战
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >Introduction</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="8scrapy&#x8C46;&#x74E3;&#x7F51;&#x767B;&#x5F55;&#x722C;&#x866B;&#x4E0E;&#x9A8C;&#x8BC1;&#x7801;&#x8BC6;&#x522B;&#x9879;&#x76EE;&#x5B9E;&#x6218;1">8.Scrapy&#x8C46;&#x74E3;&#x7F51;&#x767B;&#x5F55;&#x722C;&#x866B;&#x4E0E;&#x9A8C;&#x8BC1;&#x7801;&#x8BC6;&#x522B;&#x9879;&#x76EE;&#x5B9E;&#x6218;1</h1>
<h4 id="&#x6A21;&#x62DF;&#x6D4F;&#x89C8;&#x5668;&#x767B;&#x5F55;-&#x6D89;&#x53CA;&#x5230;&#x7684;&#x64CD;&#x4F5C;&#xFF1A;">&#x6A21;&#x62DF;&#x6D4F;&#x89C8;&#x5668;&#x767B;&#x5F55;, &#x6D89;&#x53CA;&#x5230;&#x7684;&#x64CD;&#x4F5C;&#xFF1A;</h4>
<ul>
<li><p><code>start_requests()</code>&#x65B9;&#x6CD5;&#xFF0C;&#x53EF;&#x4EE5;&#x8FD4;&#x56DE;&#x4E00;&#x4E2A;&#x8BF7;&#x6C42;&#x7ED9;&#x722C;&#x866B;&#x7684;&#x8D77;&#x59CB;&#x7F51;&#x7AD9;&#xFF0C;&#x8FD9;&#x4E2A;&#x8FD4;&#x56DE;&#x7684;&#x8BF7;&#x6C42;&#x76F8;&#x5F53;&#x4E8E;start_urls&#xFF0C;start_requests()&#x8FD4;&#x56DE;&#x7684;&#x8BF7;&#x6C42;&#x4F1A;&#x66FF;&#x4EE3;start_urls&#x91CC;&#x7684;&#x8BF7;&#x6C42;</p>
</li>
<li><p><code>Request()</code> get&#x8BF7;&#x6C42;&#xFF0C;&#x53EF;&#x4EE5;&#x8BBE;&#x7F6E;&#xFF0C;url&#x3001;cookie&#x3001;&#x56DE;&#x8C03;&#x51FD;&#x6570;</p>
</li>
<li><p><code>FormRequest.from_response()</code>&#x8868;&#x5355;post&#x63D0;&#x4EA4;&#xFF0C;&#x7B2C;&#x4E00;&#x4E2A;&#x5FC5;&#x987B;&#x53C2;&#x6570;&#xFF0C;&#x4E0A;&#x4E00;&#x6B21;&#x54CD;&#x5E94;cookie&#x7684;response&#x5BF9;&#x8C61;&#xFF0C;&#x5176;&#x4ED6;&#x53C2;&#x6570;&#xFF0C;cookie&#x3001;url&#x3001;&#x8868;&#x5355;&#x5185;&#x5BB9;&#x7B49;</p>
</li>
<li><p><code>yield Request()</code>&#x53EF;&#x4EE5;&#x5C06;&#x4E00;&#x4E2A;&#x65B0;&#x7684;&#x8BF7;&#x6C42;&#x8FD4;&#x56DE;&#x7ED9;&#x722C;&#x866B;&#x6267;&#x884C;</p>
</li>
<li><p>&#x5728;&#x53D1;&#x9001;&#x8BF7;&#x6C42;&#x65F6;cookie&#x7684;&#x64CD;&#x4F5C;&#xFF0C;</p>
</li>
<li><code>meta={&apos;cookiejar&apos;:1}</code>&#x8868;&#x793A;&#x5F00;&#x542F;cookie&#x8BB0;&#x5F55;&#xFF0C;&#x9996;&#x6B21;&#x8BF7;&#x6C42;&#x65F6;&#x5199;&#x5728;Request()&#x91CC;</li>
<li><code>meta={&apos;cookiejar&apos;:response.meta[&apos;cookiejar&apos;]}</code>&#x8868;&#x793A;&#x4F7F;&#x7528;&#x4E0A;&#x4E00;&#x6B21;response&#x7684;cookie&#xFF0C;&#x5199;&#x5728;FormRequest.from_response()&#x91CC;post&#x6388;&#x6743;</li>
<li><code>meta={&apos;cookiejar&apos;:True}</code>&#x8868;&#x793A;&#x4F7F;&#x7528;&#x6388;&#x6743;&#x540E;&#x7684;cookie&#x8BBF;&#x95EE;&#x9700;&#x8981;&#x767B;&#x5F55;&#x67E5;&#x770B;&#x7684;&#x9875;&#x9762;</li>
</ul>
<ul>
<li>&#x521B;&#x5EFA;&#x9879;&#x76EE;douban &#x548C;&#x722C;&#x866B;&#x6587;&#x4EF6;d1.py</li>
</ul>
<pre><code>    $ scrapy startproject douban

    $ cd douban

    $ scrapy genspider -t basic d1 douban.com
</code></pre><ul>
<li>&#x7F16;&#x8F91;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#xFF1A;douban/settings.py</li>
</ul>
<pre><code class="lang-python">
<span class="hljs-comment"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY = <span class="hljs-keyword">False</span>
</code></pre>
<ul>
<li>&#x7F16;&#x8F91;&#x722C;&#x866B;&#x6587;&#x4EF6;&#xFF1A;douban/spiders/d1.py</li>
</ul>
<pre><code class="lang-python"><span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">from</span> scrapy.http <span class="hljs-keyword">import</span> Request,FormRequest
<span class="hljs-keyword">import</span> urllib.request
<span class="hljs-keyword">import</span> os

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">D1Spider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&apos;d1&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;douban.com&apos;</span>]
    <span class="hljs-comment">#start_urls = [&apos;http://douban.com/&apos;]</span>
    header = {<span class="hljs-string">&quot;User-Agent&quot;</span>:<span class="hljs-string">&quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;</span>}
    <span class="hljs-comment"># &#x7F16;&#x5199;start_requests()&#x65B9;&#x6CD5;&#xFF0C;&#x7B2C;&#x4E00;&#x6B21;&#x4F1A;&#x9ED8;&#x8BA4;&#x8C03;&#x53D6;&#x8BE5;&#x65B9;&#x6CD5;&#x4E2D;&#x7684;&#x8BF7;&#x6C42;</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start_requests</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-comment"># &#x9996;&#x5148;&#x722C;&#x4E00;&#x6B21;&#x767B;&#x5F55;&#x9875;&#xFF0C;&#x7136;&#x540E;&#x8FDB;&#x5165;&#x56DE;&#x8C03;&#x51FD;&#x6570;parse&#xFF08;&#xFF09;</span>
        <span class="hljs-keyword">return</span> [Request(<span class="hljs-string">&quot;https://accounts.douban.com/login&quot;</span>,headers=self.header,meta={<span class="hljs-string">&quot;cookiejar&quot;</span>:<span class="hljs-number">1</span>},callback=self.parse)]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-comment"># &#x8BBE;&#x7F6E;&#x8981;&#x4F20;&#x9012;&#x7684;&#x53C2;&#x6570;&#xFF0C;</span>
        data = {
            <span class="hljs-string">&quot;form_email&quot;</span>:<span class="hljs-string">&quot;122794105@qq.com&quot;</span>,
            <span class="hljs-string">&quot;form_password&quot;</span>:<span class="hljs-string">&quot;douban2018&quot;</span>,
            <span class="hljs-string">&quot;redir&quot;</span>:<span class="hljs-string">&quot;https://www.douban.com/&quot;</span>,
            }
        <span class="hljs-comment"># &#x9996;&#x5148;&#x5224;&#x65AD;&#x662F;&#x5426;&#x6709;&#x9A8C;&#x8BC1;&#x7801;</span>
        captcha = response.xpath(<span class="hljs-string">&quot;//img[@id=&apos;captcha_image&apos;]/@src&quot;</span>).extract()
        <span class="hljs-keyword">if</span> len(captcha)&gt;<span class="hljs-number">0</span>:
            print(<span class="hljs-string">&quot;&#x6B64;&#x65F6;&#x6709;&#x9A8C;&#x8BC1;&#x7801;&#xFF01;&quot;</span>)
            localpath = <span class="hljs-string">&quot;./img/captcha.png&quot;</span>
            urllib.request.urlretrieve(captcha[<span class="hljs-number">0</span>],filename=localpath)
            code = input(<span class="hljs-string">&quot;&#x8BF7;&#x67E5;&#x770B;&#x56FE;&#x7247;&#x540E;&#xFF0C;&#x8F93;&#x5165;&#x9A8C;&#x8BC1;&#x7801;&quot;</span>)
            data[<span class="hljs-string">&apos;captcha-solution&apos;</span>]=code

            <span class="hljs-comment">#&#x4F7F;&#x7528;&#x63A5;&#x53E3;&#x83B7;&#x53D6;&#xFF08;&#x4E91;&#x6253;&#x7801;&#xFF09;</span>
            <span class="hljs-comment">#cmd = &quot;&quot;</span>
            <span class="hljs-comment">#r = os.popen(cmd)</span>
            <span class="hljs-comment">#data[&apos;captcha-solution&apos;]=r.read()</span>
            <span class="hljs-comment">#print(&quot;&#x9A8C;&#x8BC1;&#x7801;&#x4E3A;&#xFF1A;&quot;+data[&apos;captcha-solution&apos;])</span>

        print(<span class="hljs-string">&quot;&#x767B;&#x9646;&#x4E2D;...&quot;</span>)
        <span class="hljs-comment"># &#x901A;&#x8FC7;FormRequest.from_response()&#x8FDB;&#x884C;&#x767B;&#x9646;</span>
        <span class="hljs-keyword">return</span> [FormRequest.from_response(response,
                                    <span class="hljs-comment">#&#x8BBE;&#x7F6E;cookie&#x4FE1;&#x606F;</span>
                                    meta={<span class="hljs-string">&quot;cookiejar&quot;</span>:response.meta[<span class="hljs-string">&apos;cookiejar&apos;</span>]},
                                    <span class="hljs-comment">#&#x8BBE;&#x7F6E;headers&#x5934;&#x4FE1;&#x606F;&#x6A21;&#x62DF;&#x6210;&#x6D4F;&#x89C8;&#x5668;</span>
                                    headers=self.header,
                                    <span class="hljs-comment">#&#x8BBE;&#x7F6E;post&#x8868;&#x5355;&#x4E2D;&#x7684;&#x6570;&#x636E;</span>
                                    formdata=data,
                                    <span class="hljs-comment">#&#x8BBE;&#x7F6E;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#xFF0C;&#x6B64;&#x65F6;&#x56DE;&#x8C03;&#x51FD;&#x6570;&#x4E3A;next()</span>
                                    callback=self.next,
                                    )]
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">next</span><span class="hljs-params">(self,response)</span>:</span>
        title = response.xpath(<span class="hljs-string">&quot;/html/head/title/text()&quot;</span>).extract()
        print(title)
</code></pre>
<ul>
<li>&#x6D4B;&#x8BD5;&#x8FD0;&#x884C;&#xFF1A;</li>
</ul>
<pre><code>    $scrapy crawl d1 --nolog
</code></pre>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../scrapy/7.html" class="navigation navigation-prev " aria-label="Previous page: 7. Scrapy新闻爬虫项目实战下"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../scrapy/9.html" class="navigation navigation-next " aria-label="Next page: 9. Scrapy豆瓣网登录爬虫与验证码识别项目实战2"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
