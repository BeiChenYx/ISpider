<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>6. Scrapy新闻爬虫项目实战上 | Introduction</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../scrapy/7.html" />
    
    
    <link rel="prev" href="../scrapy/5.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="7"
        data-chapter-title="6. Scrapy新闻爬虫项目实战上"
        data-filepath="scrapy/6.md"
        data-basepath=".."
        data-revision="Sun Jan 28 2018 19:48:10 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Introduction
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        Scrapy简介
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="2" data-path="scrapy/index.html">
            
                
                    <a href="../scrapy/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        1. 认识Scrapy框架
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3" data-path="scrapy/2.html">
            
                
                    <a href="../scrapy/2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        2. Scrapy安装和使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4" data-path="scrapy/3.html">
            
                
                    <a href="../scrapy/3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        3. Scrapy常用命令实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5" data-path="scrapy/4.html">
            
                
                    <a href="../scrapy/4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        4. Scrapy实现当当网商品爬虫实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6" data-path="scrapy/5.html">
            
                
                    <a href="../scrapy/5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        5. Scrapy模拟登录实战
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="7" data-path="scrapy/6.html">
            
                
                    <a href="../scrapy/6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        6. Scrapy新闻爬虫项目实战上
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8" data-path="scrapy/7.html">
            
                
                    <a href="../scrapy/7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        7. Scrapy新闻爬虫项目实战下
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="9" data-path="scrapy/8.html">
            
                
                    <a href="../scrapy/8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>9.</b>
                        
                        8. Scrapy豆瓣网登录爬虫与验证码识别项目实战1
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="10" data-path="scrapy/9.html">
            
                
                    <a href="../scrapy/9.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>10.</b>
                        
                        9. Scrapy豆瓣网登录爬虫与验证码识别项目实战2
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="11" data-path="scrapy/10.html">
            
                
                    <a href="../scrapy/10.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>11.</b>
                        
                        10. 如何在Urillib中使用Xpath表达式
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12" data-path="week2/index.html">
            
                
                    <a href="../week2/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.</b>
                        
                        Scrapy第二周实战
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="12.1" data-path="week2/1.html">
            
                
                    <a href="../week2/1.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.1.</b>
                        
                        1. Scrapy与Urllib整合实现京东商品
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.2" data-path="week2/2.html">
            
                
                    <a href="../week2/2.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.2.</b>
                        
                        2. 淘宝商品爬虫项目实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.3" data-path="week2/3.html">
            
                
                    <a href="../week2/3.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.3.</b>
                        
                        3. BeautifulSoup基础实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.4" data-path="week2/4.html">
            
                
                    <a href="../week2/4.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.4.</b>
                        
                        4. PhantomJS基础实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.5" data-path="week2/5.html">
            
                
                    <a href="../week2/5.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.5.</b>
                        
                        5. 腾讯动漫项目爬虫实战
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.6" data-path="week2/6.html">
            
                
                    <a href="../week2/6.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.6.</b>
                        
                        6. Docker基础
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.7" data-path="week2/7.html">
            
                
                    <a href="../week2/7.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.7.</b>
                        
                        7. Redis的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="12.8" data-path="week2/8.html">
            
                
                    <a href="../week2/8.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>12.8.</b>
                        
                        8. 分布式爬虫的实战
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >Introduction</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h1 id="6scrapy&#x65B0;&#x95FB;&#x722C;&#x866B;&#x9879;&#x76EE;&#x5B9E;&#x6218;&#x4E0A;">6.Scrapy&#x65B0;&#x95FB;&#x722C;&#x866B;&#x9879;&#x76EE;&#x5B9E;&#x6218;&#x4E0A;</h1>
<ul>
<li>&#x4EFB;&#x52A1;&#xFF1A;&#x5C06;&#x767E;&#x5EA6;&#x65B0;&#x95FB;&#x9996;&#x9875;&#x7684;&#x6240;&#x6709;&#x4FE1;&#x606F;&#x7684;&#x722C;&#x53D6;&#x4E0B;&#x6765;&#xFF1A;<a href="http://news.baidu.com/" target="_blank">http://news.baidu.com/</a></li>
</ul>
<p><img src="../images/scrapy/baidunews01.png" alt=""></p>
<ul>
<li>&#x901A;&#x8FC7;&#x7F51;&#x9875;&#x6E90;&#x4EE3;&#x7801;&#x8FD8;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#x7F51;&#x9875;&#x5185;&#x5BB9;&#x3002;&#x5982;&#x4E0B;&#xFF1A;</li>
</ul>
<pre><code>...
&lt;ul class=&quot;ulist focuslistnews&quot;&gt;
&lt;li class=&quot;bold-item&quot;&gt;
&lt;span class=&quot;dot&quot;&gt;&lt;/span&gt;
&lt;a href=&quot;http://news.china.com/domesticgd/10000159/20180112/31945806.html&quot; mon=&quot;ct=1&amp;amp;a=2&amp;amp;c=top&amp;pn=1&quot; target=&quot;_blank&quot;&gt;&#x592E;&#x4F01;&#x5E74;&#x5EA6;&#x76D1;&#x7763;&#x68C0;&#x67E5;&#x60C5;&#x51B5;&#x516C;&#x5E03; &#x5229;&#x6DA6;&#x521B;&#x8FD1;&#x4E94;&#x5E74;&#x6700;&#x597D;&#x6C34;&#x5E73;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://www.cac.gov.cn/2018-01/10/c_1122234687.htm&quot; mon=&quot;ct=1&amp;amp;a=2&amp;amp;c=top&amp;pn=2&quot; target=&quot;_blank&quot;&gt;&#x56FD;&#x5BB6;&#x7F51;&#x4FE1;&#x529E;&#x7EA6;&#x8C08;&#x201C;&#x652F;&#x4ED8;&#x5B9D;&#x5E74;&#x5EA6;&#x8D26;&#x5355;&#x4E8B;&#x4EF6;&#x201D;&#x5F53;&#x4E8B;&#x4F01;&#x4E1A;&#x8D1F;&#x8D23;&#x4EBA; &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://news.ifeng.com/a/20180112/55058132_0.shtml?_zbs_baidu_news &quot; mon=&quot;ct=1&amp;amp;a=2&amp;amp;c=top&amp;pn=3&quot; target=&quot;_blank&quot;&gt;&#x591A;&#x5730;&#x53EC;&#x5F00;&#x4F4F;&#x623F;&#x57CE;&#x4E61;&#x5DE5;&#x4F5C;&#x4F1A;&#x8BAE; &#x5B9A;&#x8C03;2018&#x697C;&#x5E02;&#x8C03;&#x63A7;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://xinwen.eastday.com/a/xjump.html?id=n180112080815324&quot; mon=&quot;ct=1&amp;amp;a=2&amp;amp;c=top&amp;pn=4&quot; target=&quot;_blank&quot;&gt;12&#x90E8;&#x59D4;&#x9996;&#x6B21;&#x63A8;&#x51FA;&#x7164;&#x70AD;&#x4E1A;&#x91CD;&#x7EC4;&#x4E13;&#x95E8;&#x6587;&#x4EF6; &#x517C;&#x5E76;&#x5927;&#x6F6E;&#x5C06;&#x8D77; &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://news.ifeng.com/a/20180112/55058103_0.shtml?_zbs_baidu_news &quot; mon=&quot;ct=1&amp;amp;a=2&amp;amp;c=top&amp;pn=5&quot; target=&quot;_blank&quot;&gt;2017&#x5E74;&#x56FD;&#x5BB6;&#x79D1;&#x6280;&#x5956;&#x83B7;&#x5956;&#x9879;&#x76EE;&#x5DE1;&#x793C;&#xFF1A;&#x89E3;&#x5BC6;&#x521B;&#x65B0;&#x4E4B;&#x8DEF;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://xinwen.eastday.com/a/xjump.html?id=n180112085639420&quot; mon=&quot;ct=1&amp;amp;a=2&amp;amp;c=top&amp;pn=6&quot; target=&quot;_blank&quot;&gt;&#x73AF;&#x4FDD;&#x90E8;&#xFF1A;12&#x65E5;&#x8D77;&#x4EAC;&#x6D25;&#x5180;&#x53CA;&#x5468;&#x8FB9;&#x5C06;&#x51FA;&#x73B0;&#x91CD;&#x6C61;&#x67D3;&#x5929;&#x6C14;&#x8FC7;&#x7A0B;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
...
</code></pre><ul>
<li>&#x4F46;&#x662F;&#x7F51;&#x9875;&#x7684;&#x7B2C;&#x4E8C;&#x5C4F;&#x5185;&#x5BB9;&#xFF0C;&#x5728;&#x7F51;&#x9875;&#x6E90;&#x4EE3;&#x7801;&#x4E2D;&#x5C31;&#x6CA1;&#x6709;&#x4FE1;&#x606F;&#x4E86;&#xFF1A;&#x5982;&#x4E0B;&#xFF1A;</li>
</ul>
<p><img src="../images/scrapy/baidunews02.png" alt=""></p>
<ul>
<li>&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x7F51;&#x9875;&#x8C03;&#x8BD5;&#x6A21;&#x5F0F;&#x67E5;&#x770B;&#x5230;&#x4E0B;&#x9762;&#x7684;&#x8BF7;&#x6C42;&#x5185;&#x5BB9;&#xFF1A;&#x662F;&#x901A;&#x8FC7;Ajax&#x540E;&#x7EED;&#x52A0;&#x8F7D;&#x7684;</li>
</ul>
<p><img src="../images/scrapy/baidunews03.png" alt=""></p>
<h4 id="61-&#x5206;&#x6790;&#xFF1A;">6.1 &#x5206;&#x6790;&#xFF1A;</h4>
<ul>
<li><p>&#x5EF6;&#x8FDF;&#x52A0;&#x8F7D;&#x7684;&#x5176;&#x4ED6;&#x65B0;&#x95FB;&#x5730;&#x5740;&#x4E3A;&#xFF1A;</p>
</li>
<li><p>&#x56FD;&#x5185;&#xFF1A;<a href="http://news.baidu.com/widget?id=civilnews&amp;t=1515727849441" target="_blank">http://news.baidu.com/widget?id=civilnews&amp;t=1515727849441</a></p>
</li>
<li>&#x56FD;&#x9645;&#xFF1A;<a href="http://news.baidu.com/widget?id=InternationalNews&amp;t=1515727849455" target="_blank">http://news.baidu.com/widget?id=InternationalNews&amp;t=1515727849455</a></li>
<li>&#x5A31;&#x4E50;&#xFF1A;<a href="http://news.baidu.com/widget?id=EnterNews&amp;t=1515727849476" target="_blank">http://news.baidu.com/widget?id=EnterNews&amp;t=1515727849476</a></li>
<li>&#x4F53;&#x80B2;&#xFF1A;<a href="http://news.baidu.com/widget?id=SportNews&amp;t=1515727849533" target="_blank">http://news.baidu.com/widget?id=SportNews&amp;t=1515727849533</a></li>
<li>&#x8D22;&#x7ECF;&#xFF1A;<a href="http://news.baidu.com/widget?id=FinanceNews&amp;t=1515727849631" target="_blank">http://news.baidu.com/widget?id=FinanceNews&amp;t=1515727849631</a></li>
<li>&#x79D1;&#x6280;&#xFF1A;<a href="http://news.baidu.com/widget?id=TechNews&amp;t=1515727849790" target="_blank">http://news.baidu.com/widget?id=TechNews&amp;t=1515727849790</a></li>
<li>&#x793E;&#x4F1A;&#xFF1A;<a href="http://news.baidu.com/widget?id=SocialNews&amp;t=1515727849858" target="_blank">http://news.baidu.com/widget?id=SocialNews&amp;t=1515727849858</a></li>
<li>&#x519B;&#x4E8B;&#xFF1A;<a href="http://news.baidu.com/widget?id=MilitaryNews&amp;t=1515727850011" target="_blank">http://news.baidu.com/widget?id=MilitaryNews&amp;t=1515727850011</a></li>
<li>&#x4E92;&#x8054;&#x7F51;&#xFF1A;<a href="http://news.baidu.com/widget?id=InternetNews&amp;t=1515727850044" target="_blank">http://news.baidu.com/widget?id=InternetNews&amp;t=1515727850044</a></li>
<li>&#x63A2;&#x7D22;&#xFF1A;<a href="http://news.baidu.com/widget?id=DiscoveryNews&amp;t=1515727850077" target="_blank">http://news.baidu.com/widget?id=DiscoveryNews&amp;t=1515727850077</a></li>
<li>&#x5973;&#x4EBA;&#xFF1A;<a href="http://news.baidu.com/widget?id=LadyNews&amp;t=1515727850110" target="_blank">http://news.baidu.com/widget?id=LadyNews&amp;t=1515727850110</a></li>
<li>&#x5065;&#x5EB7;&#xFF1A;<a href="http://news.baidu.com/widget?id=HealthNews&amp;t=1515727850228" target="_blank">http://news.baidu.com/widget?id=HealthNews&amp;t=1515727850228</a></li>
</ul>
<h3 id="61">6.1</h3>
<ul>
<li>&#x521B;&#x5EFA;&#x767E;&#x5EA6;&#x65B0;&#x95FB;&#x722C;&#x866B;scrapy&#x9879;&#x76EE;</li>
</ul>
<pre><code>F:\Python02&gt;scrapy startproject baidunews
New Scrapy project &apos;baidunews&apos;, using template directory &apos;c:\\users\\administrat
or\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\scrapy\\t
emplates\\project&apos;, created in:
    F:\Python02\baidunews

You can start your first spider with:
    cd baidunews
    scrapy genspider example example.com
</code></pre><ul>
<li>&#x521B;&#x5EFA;&#x722C;&#x866B;&#x6587;&#x4EF6;:n1.py</li>
</ul>
<pre><code>F:\Python02\baidunews&gt;scrapy genspider -t basic n1 baidu.com
Created spider &apos;n1&apos; using template &apos;basic&apos; in module:
  baidunews.spiders.n1

F:\Python02\baidunews&gt;
</code></pre><ul>
<li>&#x5B9A;&#x4E49;&#x6293;&#x53D6;&#x6570;&#x636E;&#x683C;&#x5F0F;&#xFF1A;baidunews/items.py&#x6587;&#x4EF6;</li>
</ul>
<pre><code class="lang-python">
<span class="hljs-comment"># -*- coding: utf-8 -*-</span>

<span class="hljs-comment"># Define here the models for your scraped items</span>
<span class="hljs-comment">#</span>
<span class="hljs-comment"># See documentation in:</span>
<span class="hljs-comment"># https://doc.scrapy.org/en/latest/topics/items.html</span>

<span class="hljs-keyword">import</span> scrapy


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BaidunewsItem</span><span class="hljs-params">(scrapy.Item)</span>:</span>
    <span class="hljs-comment"># define the fields for your item here like:</span>
    <span class="hljs-comment"># name = scrapy.Field()</span>
    title = scrapy.Field()
    link = scrapy.Field()
    content = scrapy.Field()
</code></pre>
<ul>
<li>&#x66F4;&#x6539;&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#xFF1A;baidunews/settings.py</li>
</ul>
<pre><code class="lang-python">...
<span class="hljs-comment"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY = <span class="hljs-keyword">False</span>
...

<span class="hljs-comment"># Configure item pipelines</span>
<span class="hljs-comment"># See https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span>
ITEM_PIPELINES = {
    <span class="hljs-string">&apos;baidunews.pipelines.BaidunewsPipeline&apos;</span>: <span class="hljs-number">300</span>,
}
...
</code></pre>
<ul>
<li>&#x7F16;&#x8F91;&#x722C;&#x866B;&#x6587;&#x4EF6;&#xFF1A;baidunews/spiders/n1.py</li>
</ul>
<pre><code class="lang-python">
<span class="hljs-comment"># -*- coding: utf-8 -*-</span>
<span class="hljs-keyword">import</span> scrapy
<span class="hljs-keyword">from</span> baidunews.items <span class="hljs-keyword">import</span> BaidunewsItem
<span class="hljs-keyword">from</span> scrapy.http <span class="hljs-keyword">import</span> Request
<span class="hljs-keyword">import</span> re


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">N1Spider</span><span class="hljs-params">(scrapy.Spider)</span>:</span>
    name = <span class="hljs-string">&apos;n1&apos;</span>
    allowed_domains = [<span class="hljs-string">&apos;baidu.com&apos;</span>]
    start_urls = [<span class="hljs-string">&apos;http://news.baidu.com/&apos;</span>]
    header = {<span class="hljs-string">&quot;User-Agent&quot;</span>:<span class="hljs-string">&quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.115 Safari/537.36&quot;</span>}
    urllist=[<span class="hljs-string">&apos;http://news.baidu.com/widget?id=civilnews&amp;t=1515727849441&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=InternationalNews&amp;t=1515727849455&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=EnterNews&amp;t=1515727849476&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=SportNews&amp;t=1515727849533&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=FinanceNews&amp;t=1515727849631&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=TechNews&amp;t=1515727849790&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=SocialNews&amp;t=1515727849858&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=MilitaryNews&amp;t=1515727850011&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=InternetNews&amp;t=1515727850044&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=DiscoveryNews&amp;t=1515727850077&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=LadyNews&amp;t=1515727850110&apos;</span>,
        <span class="hljs-string">&apos;http://news.baidu.com/widget?id=HealthNews&amp;t=1515727850228&apos;</span>,
        ]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-comment">#data = response.body.decode(&quot;utf-8&quot;,&quot;ignore&quot;)</span>
        <span class="hljs-comment">#urls = response.xpath(&quot;//ul[@class=&apos;ulist focuslistnews&apos;]/li/a/@href&quot;).extract()</span>
        <span class="hljs-comment">#for i in range(0,len(urls)):</span>
        <span class="hljs-comment">#    print(urls[i])</span>
        <span class="hljs-comment">#    yield Request(urls[i],callback=self.next2)</span>

        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>,len(self.urllist)):
            <span class="hljs-keyword">yield</span> Request(self.urllist[j],callback=self.next1)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">next1</span><span class="hljs-params">(self, response)</span>:</span>
        <span class="hljs-comment">#data = response.body.decode(&quot;utf-8&quot;,&quot;ignore&quot;)</span>
        urls = response.xpath(<span class="hljs-string">&quot;//ul[@class=&apos;ulist focuslistnews&apos;]/li/a/@href&quot;</span>).extract()
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">0</span>,len(urls)):
            print(urls[i])
            <span class="hljs-keyword">yield</span> Request(urls[i],callback=self.next2)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">next2</span><span class="hljs-params">(self,response)</span>:</span>
        <span class="hljs-comment">#print(&quot;aaaa&quot;)</span>
        item = BaidunewsItem()
        item[<span class="hljs-string">&apos;title&apos;</span>] = response.xpath(<span class="hljs-string">&quot;/html/head/title/text()&quot;</span>).extract()
        item[<span class="hljs-string">&apos;link&apos;</span>] = response.url
        item[<span class="hljs-string">&apos;content&apos;</span>] = response.body
        <span class="hljs-comment">#print(item[&apos;title&apos;])</span>
        <span class="hljs-keyword">yield</span> item
</code></pre>
<ul>
<li>&#x6D4B;&#x8BD5;&#xFF1A;</li>
</ul>
<pre><code>    $ scrapy crawl n1 --nolog
</code></pre>
                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../scrapy/5.html" class="navigation navigation-prev " aria-label="Previous page: 5. Scrapy模拟登录实战"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../scrapy/7.html" class="navigation navigation-next " aria-label="Next page: 7. Scrapy新闻爬虫项目实战下"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
